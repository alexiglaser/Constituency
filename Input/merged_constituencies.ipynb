{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proportional representation of UK constituencies\n",
    "\n",
    "The idea behind this project is to see how a proportional representation system would have altered results in the last UK general election. The plan is to merge neighbouring constituencies in the UK into 'super' constituencies with 2 / 3 / 4 / etc of them merged together into a larger one and use the D'Hondt method to allocate seats in this 'super' constituency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gp.read_file(\"../Data/Westminster_Parliamentary_Constituencies_December_2017_UK_BFC/Westminster_Parliamentary_Constituencies_December_2017_UK_BFC.shp\")\n",
    "df = df.rename(columns={\"PCON17NM\": \"Name\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's scrape wikipedia for details about the UK constituencies, namely which region they are in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/United_Kingdom_Parliament_constituencies\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "constituencies_table = soup.findAll('table',{'class':'wikitable sortable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_dict = {}\n",
    "countries = ['England','Scotland','Wales','Northern Ireland']\n",
    "for i in range(len(constituencies_table)):\n",
    "    for items in constituencies_table[i].findAll('tr')[1:]:\n",
    "        data = items.find_all(['th','td'])\n",
    "        try:\n",
    "            constituency = data[0].a.text\n",
    "            electorate_2017 = data[1].text\n",
    "            county = data[2].a.text\n",
    "            if i == 0:\n",
    "                region = data[3].text[:-1] # Remove the \"\\n\"\n",
    "            else:\n",
    "                region = countries[i]\n",
    "        except IndexError:pass\n",
    "        const_dict[constituency] = pd.DataFrame.from_records(\n",
    "            [{'constituency': constituency, 'electorate_2017': electorate_2017, 'county': county, 'region': region}] #, index=constituency\n",
    "        )\n",
    "const_df = pd.concat(const_dict).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bit of string replacement so that we can merge the datasets.\n",
    "for i in range(len(const_df['constituency'])):\n",
    "    const = const_df['constituency'][i]\n",
    "    if 'St ' in const:\n",
    "        const_df['constituency'][i] = str.replace(const_df['constituency'][i], \"St \", \"St. \")\n",
    "    # Also need to remove the '么' in \"Ynys M么n\" \n",
    "    if '么' in const:\n",
    "        const_df['constituency'][i] = str.replace(const_df['constituency'][i], \"么\", \"o\")\n",
    "# Now merge new information\n",
    "# df['constituency'] = [x.rsplit(' ', 1)[0].rsplit(' ', 1)[0] for x in df['name']]\n",
    "df = df.merge(const_df, left_on='Name', right_on='constituency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plan is to take every single constituency and find the 'neighbouring' constituency. We will use the 'disjoint' function from geopandas to\n",
    "# find is two constituencies are not bordering.\n",
    "# This will only be done on a region by region basis, as we are not interested in, say a Scotish constiuency that borders one in North \n",
    "# Eastern England.\n",
    "# Create a pair and then see if we can use the Algorithm X to fit them into a region.\n",
    "pair_const = {}\n",
    "k = 0\n",
    "for i in range(len(df)):\n",
    "    iregion = df['region'][i]\n",
    "    for j in range(i+1, len(df)):\n",
    "        if (df['region'][j] == iregion):\n",
    "            if not df.geometry[i].disjoint(df.geometry[j]):\n",
    "                k += 1\n",
    "                pair_const[k] = pd.DataFrame({'region': [iregion], 'pairing': k, 'name1': [df['Name'][i]], 'name2': [df['Name'][j]]})\n",
    "const_pairs = pd.concat(pair_const).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Isle of Wight', 'Orkney and Shetland', 'Na h-Eileanan an Iar', 'Ynys Mon'}\n"
     ]
    }
   ],
   "source": [
    "# Now need to find all constituencies which haven't got a neighbouring constituency\n",
    "paired_const = set(const_pairs['name1']).union(set(const_pairs['name2']))\n",
    "unpaired_const = set(df['Name']).difference(paired_const)\n",
    "print(unpaired_const)\n",
    "# For the moment we will leave these out. \n",
    "# One reason is that 'Isle of Wight', 'Na h-Eileanan an Iar' and 'Orkney and Shetland' have protected status so that they have constituency\n",
    "# boundaries defined exclusively by geography rather than by (or partly by) size of electorate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find merged constituencies of size 2 we can use the data frame `paired_const` fitered to just one region and then creating a dictionary which follows directly from the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "from algo_x import *\n",
    "\n",
    "def all_solns(const_pairs, region):\n",
    "    df = const_pairs[const_pairs['region'] == region_name]\n",
    "    Y = {}\n",
    "    for i in range(len(df)):\n",
    "        Y[df2['pairing'].iloc[i]] = {df['name1'].iloc[i], df['name2'].iloc[i]}\n",
    "\n",
    "    all_solns = ExactCover(Y, random = True)\n",
    "    i = 0\n",
    "    for a in all_solns:\n",
    "        i += 1\n",
    "    # Find out how many constituencies there are in the dictionary.\n",
    "    X = set([x for y in Y.values() for x in y])\n",
    "    print(f\"For the {region} region there are {i} solutions when there are {len(X)} constituencies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Northern Ireland region there are 129 solutions when there are 18 constituencies.\n",
      "The time taken is 0.0119s\n"
     ]
    }
   ],
   "source": [
    "region_name = 'Northern Ireland'\n",
    "start = time.time()\n",
    "all_solns(const_pairs, region_name)\n",
    "end = time.time()\n",
    "print(f\"The time taken is {end - start:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That works out quite nicely, however there are only 18 constituencies in the Northern Ireland region and it also contains an even number of constituencies. If we repeat the above for the 'North East' we will not have any solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the North East region there are 0 solutions when there are 29 constituencies.\n",
      "The time taken is 0.0108s\n"
     ]
    }
   ],
   "source": [
    "region_name = 'North East'\n",
    "start = time.time()\n",
    "all_solns(const_pairs, region_name)\n",
    "end = time.time()\n",
    "print(f\"The time taken is {end - start:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible solutions might be to remove one constituency at random, however this can seriously affect the number of solutions, especially for constituencies with few neighbours. E.G. York Central is completely covered by York Outer, so if we removed York Outer then there would be no solutions.\n",
    "\n",
    "An initial thought would be to find a three way neighbour at random and have that as part of the solution. How to implement this is a bit more complex, though shouldn't be too hard if we want the 'super' constituencies to be of size 2; however if we want the majority to be of size 3 then we would end up in a situation for e.g. London with 73 constituencies having 23 three-merged constituencies and 2 two-merged constituencies. How to implement these may be tougher. Also does this three-merged constituenciy stay constant for all of our solutions (definitely not) or do we change it with every possible solution (yes we would, but how would that impact on the time taken).\n",
    "\n",
    "In addition one other issue we face with the ExactCover code is that it returns all known solutions. This isn't a problem for some of the regions, but e.g. London, kept running for several hours and still didn't complete. Ideally we would want at least 10,000 solutions for each possible region (where this is possible). We would also really want to change the code so that the starting criteria is more random. At present it appears to start off in the same place every time, since the code is written to find every solution, which is sub-optimal for what we want to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future plans:\n",
    "Once the issue with the Exact Cover is solved we would need to get all of the results of the UK general election in 2019 (and possibly previous elections). \n",
    "\n",
    "Using the solutions we would aggregate the constiuency election results together and apply the D'Hondt method for up to, say 10,000, simulations and report results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
