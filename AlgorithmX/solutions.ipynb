{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm X application to constituency data\n",
    "\n",
    "Previously we found all sets of 2 / 3 / 4 constituencies which are neighbours, i.e. those constituencies which share a border, which we shall call sets (with a unique identifier `set_no`). We will now apply Algorithm X to these merged constituencies and find (a subset of) solutions so that every constituency is selected once and only once. We shall do this on a region-by-region basis for two reasons:\n",
    "\n",
    "1. it will reduce the amount of possible combinations substantially\n",
    "1. it also (mostly) ensures consistency of political parties, so that e.g. we wouldn't have one constituency on England and one in Wales, so that Plaid Cymru vote would potentially halve.\n",
    "\n",
    "There are often times when the total number of constituencies in a region is not divisible by 2 / 3 / 4. For these cases we shall remove a set from a different constituency size until they are divisible, e.g. for the North East we have 29 constituencies so if we want to find all solutions where we merge 2 constituencies we shall pick at random one of the sets where 3 constituencies have been merged and remove them from our initial analysis. We shall repeat this, removing another of the 3-way merged sets, until we get a large enough sample.\n",
    "\n",
    "For some of the sets we have a large number of solutions, so we will only keep a subset of them. When there are a large number of solutions we shall rerun the analysis with the dataframe resampled and this can change the initial solutions given.\n",
    "\n",
    "The (sampled) solutions will be saved as csv files.\n",
    "\n",
    "All functions used are stored in the `algox_modules.py` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from AlgorithmX_timeout import *\n",
    "from joblib import Parallel, delayed\n",
    "from random import random, sample\n",
    "from algox_modules import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_pairs = pd.read_csv(\"../Analysis/Data/const_pairs.csv.gz\")\n",
    "const_tris = pd.read_csv(\"../Analysis/Data/const_tris.csv.gz\")\n",
    "const_quads = pd.read_csv(\"../Analysis/Data/const_quads.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = np.unique(const_pairs['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘Logs/check/solns_*.csv’: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# Remove any files that were created in a previous run\n",
    "!rm Logs/solns/soln_*.csv\n",
    "!rm Logs/log_*.log\n",
    "!rm Logs/DataFrames/df_*.csv.gz\n",
    "!rm Solutions/solns_*.csv.gz\n",
    "!rm Logs/check/solns_*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# Command to run with joblib.\n",
    "element_information = Parallel(n_jobs=4, verbose=10)(\n",
    "    delayed(get_solns)(const_pairs, const_tris, const_quads, seats, region, max_solns=1e6) \n",
    "        for region in regions for seats in [2,3,4] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'AlgorithmX_timeout' from '/home/work/AlgorithmX/AlgorithmX_timeout.py'>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import importlib\n",
    "importlib.reload(sys.modules['algox_modules'])\n",
    "importlib.reload(sys.modules['AlgorithmX_timeout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.rea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For region East with 2 seats, there were 97,178 solutions.\n",
      "For region East with 3 seats, there were 877,463 solutions.\n",
      "For region East with 4 seats, there were 68,750 solutions.\n",
      "For region East Midlands with 2 seats, there were 185,837 solutions.\n",
      "For region East Midlands with 3 seats, there were 442,937 solutions.\n",
      "For region East Midlands with 4 seats, there were 68,750 solutions.\n",
      "For region London with 2 seats, there were 68,750 solutions.\n",
      "For region London with 3 seats, there were 68,750 solutions.\n",
      "For region London with 4 seats, there were 68,750 solutions.\n",
      "For region North East with 2 seats, there were 304 solutions.\n",
      "For region North East with 3 seats, there were 803 solutions.\n",
      "For region North East with 4 seats, there were 2,153 solutions.\n",
      "For region North West with 2 seats, there were 6,875 solutions.\n",
      "For region North West with 3 seats, there were 68,750 solutions.\n",
      "For region North West with 4 seats, there were 68,750 solutions.\n",
      "For region Northern Ireland with 2 seats, there were 129 solutions.\n",
      "For region Northern Ireland with 3 seats, there were 429 solutions.\n",
      "For region Northern Ireland with 4 seats, there were 711 solutions.\n",
      "For region Scotland with 2 seats, there were 156,439 solutions.\n",
      "For region Scotland with 3 seats, there were 6,875 solutions.\n",
      "For region Scotland with 4 seats, there were 68,750 solutions.\n",
      "For region South East with 2 seats, there were 68,750 solutions.\n",
      "For region South East with 3 seats, there were 68,750 solutions.\n",
      "For region South East with 4 seats, there were 68,750 solutions.\n",
      "For region South West with 2 seats, there were 8,688 solutions.\n",
      "For region South West with 3 seats, there were 64,224 solutions.\n",
      "For region South West with 4 seats, there were 68,750 solutions.\n",
      "For region Wales with 2 seats, there were 24,786 solutions.\n",
      "For region Wales with 3 seats, there were 134,675 solutions.\n",
      "For region Wales with 4 seats, there were 68,750 solutions.\n",
      "For region West Midlands with 2 seats, there were 68,750 solutions.\n",
      "For region West Midlands with 3 seats, there were 68,750 solutions.\n",
      "For region West Midlands with 4 seats, there were 68,750 solutions.\n",
      "For region Yorkshire and The Humber with 2 seats, there were 6,875 solutions.\n",
      "For region Yorkshire and The Humber with 3 seats, there were 68,750 solutions.\n",
      "For region Yorkshire and The Humber with 4 seats, there were 68,750 solutions.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "files = np.sort(glob.glob(\"Solutions/solns_*.csv.gz\"))\n",
    "for file in files:\n",
    "    solns = pd.read_csv(file)\n",
    "    region = re.sub(\"_[0-9].csv.gz\", \"\", file.replace(\"Solutions/solns_\", \"\"))\n",
    "    seats = int(re.findall(\"[0-9]+\", file)[0])\n",
    "    print(f\"For region {region.replace('_', ' ')} with {seats} seats, there were {len(solns):,} solutions.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For region London with 4 seats, max time taken = 97.237\n",
      "For region Wales with 3 seats, max time taken = 14.909\n",
      "For region South East with 2 seats, max time taken = 27.015\n",
      "For region Northern Ireland with 3 seats, max time taken = 0.383\n",
      "For region South East with 3 seats, max time taken = 20.23\n",
      "For region Northern Ireland with 2 seats, max time taken = 0.158\n",
      "For region Wales with 2 seats, max time taken = 6.46\n",
      "For region London with 2 seats, max time taken = 26.601\n",
      "For region London with 3 seats, max time taken = 91.611\n",
      "For region South East with 4 seats, max time taken = 27.32\n",
      "For region Northern Ireland with 4 seats, max time taken = 1.304\n",
      "For region Wales with 4 seats, max time taken = 10.959\n",
      "For region East Midlands with 4 seats, max time taken = 17.212\n",
      "For region North West with 2 seats, max time taken = 3.034\n",
      "For region North West with 3 seats, max time taken = 16.412\n",
      "For region East Midlands with 2 seats, max time taken = 34.908\n",
      "For region East Midlands with 3 seats, max time taken = 74.388\n",
      "For region North West with 4 seats, max time taken = 15.512\n",
      "For region Scotland with 4 seats, max time taken = 13.391\n",
      "For region South West with 2 seats, max time taken = 3.765\n",
      "For region West Midlands with 4 seats, max time taken = 95.265\n",
      "For region East with 4 seats, max time taken = 13.969\n",
      "For region South West with 3 seats, max time taken = 11.227\n",
      "For region Scotland with 3 seats, max time taken = 8.937\n",
      "For region Scotland with 2 seats, max time taken = 43.469\n",
      "For region South West with 4 seats, max time taken = 13.079\n",
      "For region East with 3 seats, max time taken = 216.698\n",
      "For region West Midlands with 2 seats, max time taken = 21.614\n",
      "For region West Midlands with 3 seats, max time taken = 14.206\n",
      "For region East with 2 seats, max time taken = 20.306\n",
      "For region North East with 2 seats, max time taken = 0.24\n",
      "For region Yorkshire and The Humber with 3 seats, max time taken = 12.609\n",
      "For region Yorkshire and The Humber with 2 seats, max time taken = 3.802\n",
      "For region North East with 3 seats, max time taken = 1.625\n",
      "For region North East with 4 seats, max time taken = 1.169\n",
      "For region Yorkshire and The Humber with 4 seats, max time taken = 13.737\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "files = glob.glob(\"Logs/log_*.log\")\n",
    "for file in files:\n",
    "    fo = open(file, \"r+\")\n",
    "    logs = fo.readlines()\n",
    "    times = [datetime.strptime(re.findall(r\"\\d\\d\\d\\d-\\d\\d-\\d\\d\\s+\\d+:\\d+:\\d+,\\d+\", l)[0], \n",
    "                               \"%Y-%m-%d %H:%M:%S,%f\") for l in logs]\n",
    "    secs = [d.total_seconds() for d in np.diff(times)]\n",
    "    region = re.sub(\"_[0-9]+.log\", \"\", file.replace(\"Logs/log_\", \"\"))\n",
    "    seats = int(re.findall(\"[0-9]+\", file)[0])\n",
    "    print(f\"For region {region.replace('_', ' ')} with {seats} seats, max time taken = {max(secs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [datetime.strptime(re.findall(r\"\\d\\d\\d\\d-\\d\\d-\\d\\d\\s+\\d+:\\d+:\\d+,\\d+\", l)[0], \"%Y-%m-%d %H:%M:%S,%f\") for l in logs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.32"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secs = [d.total_seconds() for d in np.diff(times)]\n",
    "max(secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_describe = pd.DataFrame(secs)\n",
    "max(df_describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INFO: 2020-06-10 10:41:53,795: Starting code for region South East with 4 seats.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(17, 29), match='10:41:53,795'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(\"[0-9]+:[0-9]+:[0-9]+,[0-9]+\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10:41:53,795']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# m = re.search(\"\\d+:\\d+:\\d+,\\d+\", s)\n",
    "# if m:\n",
    "#     m.group(1)\n",
    "try:\n",
    "    found = re.findall(r\"\\d+:\\d+:\\d+,\\d+\", s)\n",
    "except AttributeError:\n",
    "    # AAA, ZZZ not found in the original string\n",
    "    found = '' # apply your error handling\n",
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fo.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_solns(const_pairs, const_tris, const_quads, 3, \"East\", max_solns=5e5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "for region in regions:\n",
    "    for seats in [2,3,4]:\n",
    "        print(f\"Region {region} with {seats} seats. Start time {datetime.datetime.now()}\")\n",
    "        get_solns(const_pairs, const_tris, const_quads, seats, region, max_solns=5e5) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Command to run with joblib.\n",
    "element_information = Parallel(n_jobs=4, verbose=10)(\n",
    "    delayed(get_solns)(const_pairs, const_tris, const_quads, seats, region, max_solns=5e5) \n",
    "        for region in regions for seats in [2,3,4] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "importlib.reload(sys.modules['algox_modules'])\n",
    "importlib.reload(sys.modules['AlgorithmX_timeout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to run with joblib.\n",
    "element_information = Parallel(n_jobs=4, verbose=10)(\n",
    "    delayed(get_solns)(const_pairs, const_tris, const_quads, seats, region, max_solns=2.5e5) \n",
    "        for region in regions for seats in [2,3,4] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "soln_dict = {}\n",
    "for i in range(15):\n",
    "    files = glob.glob(f\"Logs/solns/soln_East_3_d_{i}.csv\")\n",
    "    if len(files) == 1:\n",
    "        soln_dict[i] = pd.read_csv(files[0])\n",
    "    else:\n",
    "        files = glob.glob(f\"Logs/solns/soln_East_3_d_{i}_*.csv\")\n",
    "        d = {}\n",
    "        for file in files:\n",
    "            j = int(file.replace(\".csv\", \"\").replace(\"Logs/solns/soln_East_3_d_\", \"\").split(\"_\")[1])\n",
    "            d[j] = pd.read_csv(file)\n",
    "        try:\n",
    "            soln_dict[i] = pd.concat(d, ignore_index=True)\n",
    "        except:\n",
    "            print(f\"For i = {i} cannot concatenate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(soln_dict)):\n",
    "    print(soln_dict[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soln_dict[6].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soln_dict[1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solns = pd.concat(soln_dict) #, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"Logs/solns/soln_East_3_d_10_11.csv\"\n",
    "int(file.replace(\".csv\", \"\").replace(\"Logs/solns/soln_East_3_d_\", \"\").split(\"_\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in regions:\n",
    "    r = region.replace(\" \", \"_\")\n",
    "    try:\n",
    "#         test2 = pd.read_csv(f\"Solutions/solns_{r}_2.csv.gz\")\n",
    "#         test3 = pd.read_csv(f\"Solutions/solns_{r}_3.csv.gz\")\n",
    "        test4 = pd.read_csv(f\"Solutions/solns_{r}_4.csv.gz\")\n",
    "        print(f\"We have {test4.shape[0]:,} solutions for the {region} region for 4 seats respectively.\")\n",
    "#         print(f\"We have {test2.shape[0]:,}, {test3.shape[0]:,} and {test4.shape[0]:,} solutions for the {region} region for 2, 3 and 4 seats respectively.\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_solns(const_pairs, const_tris, const_quads, 4, \"East Midlands\", max_solns=5e5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f\"Solutions/solns_Scotland_3.csv.gz\")\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to run with joblib.\n",
    "element_information = Parallel(n_jobs=4, verbose=10)(\n",
    "    delayed(get_solns)(const_pairs, const_tris, const_quads, seats, region, max_solns=5e5) \n",
    "        for region in regions for seats in [2,3,4] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob(f\"Logs/solns/soln_*_[0-9]_d_[0-9].csv\")\n",
    "all_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 'West_Midlands'\n",
    "s = 3\n",
    "files = glob.glob(f\"Logs/solns/soln_{r}_{s}_d_[0-9].csv\")\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in ['Wales']: # regions:\n",
    "    r = region.replace(\" \", \"_\")\n",
    "    for s in [2, 3]:\n",
    "        files = glob.glob(f\"Logs/solns/soln_{r}_{s}_d_[0-9].csv\")\n",
    "        print(f\"{region}: {s} has {len(files)} files.\")\n",
    "        if len(files) > 0:\n",
    "            for file in files:\n",
    "                i = re.findall(\"[0-9]\", file)[1]\n",
    "                d[i] = pd.read_csv(file, converters={'soln': literal_eval})\n",
    "            test = pd.concat(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "from ast import literal_eval\n",
    "for region in regions:\n",
    "    print(region)\n",
    "    r = region.replace(\" \", \"_\")\n",
    "    for seats in [3]:\n",
    "        print(seats)\n",
    "        files = glob.glob(f\"Logs/solns/soln_{r}_{seats}_d_*.csv\")\n",
    "        d = {}\n",
    "        for file in files:\n",
    "            print(file)\n",
    "            i = re.findall(\"[0-9]\", file)[1]\n",
    "            print(i)\n",
    "            d[i] = pd.read_csv(file, converters={'soln': literal_eval})\n",
    "#             print(d[i].shape)\n",
    "            \n",
    "            \n",
    "        test = pd.concat(d)\n",
    "#             print(file)\n",
    "#             print(re.findall(\"[0-9]\", file)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?re.findall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail -f \"Logs/log_East_3.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def const_mapper(df):\n",
    "    \"\"\"\n",
    "    As the AlgorithmX code requires inputs starting from zero we shall take all values in the dataframes\n",
    "    and map them to ints. This function will return the solver required.\n",
    "    The df is always randomly resampled when we run this so that we get a different initial answer each time.\n",
    "    \"\"\"\n",
    "    name_cols = get_name_cols(df)\n",
    "    const_list = np.unique(df[name_cols].stack())\n",
    "    n = len(const_list)\n",
    "    mapping = {}\n",
    "    for i in range(n):\n",
    "        mapping[const_list[i]] = i\n",
    "    for col in name_cols:\n",
    "        df = df.replace({col: mapping})\n",
    "    solver = AlgorithmX(n)\n",
    "    for index, row in df.iterrows():\n",
    "        solver.appendRow([r for r in row[name_cols]], row['set_no'])\n",
    "    return solver\n",
    "\n",
    "def return_solutions(df, max_soln = 1e7, resampled=False, log_df_name=None):\n",
    "    \"\"\"\n",
    "    This function returns the solutions from the AlgorithmX code.\n",
    "    prop - states what proportion of the solutions are returned (useful for when they get too big)\n",
    "    max_soln - maximum number of solutions to derive\n",
    "    resampled - is this solution being rerun\n",
    "    \"\"\"\n",
    "    max_returned = 2.5e6\n",
    "    \n",
    "    solver = const_mapper(df)\n",
    "    solns = 0\n",
    "    dict_solns = {}\n",
    "    try:\n",
    "        with timeout(90, exception=RuntimeError): \n",
    "            # Stop calculations if taking too long, either there is no solution or having difficulty finding first one\n",
    "            for solution in solver.solve():\n",
    "                dict_solns[solns] = solution\n",
    "                solns += 1\n",
    "                if solns == max_soln:\n",
    "                    resampled = True # As we will be rerunning this with a dataframe 'resampled' data frame\n",
    "                    break\n",
    "            soln_returned = solns > 0\n",
    "\n",
    "            # If the result is too big take a sample. If the solution is going to be resampled take a small proportion\n",
    "            # otherwise take a larger one\n",
    "            if soln_returned:\n",
    "                if not resampled and solns <= max_returned:\n",
    "                    sampled_solns = pd.DataFrame({'soln': dict_solns}).reset_index(drop=True)\n",
    "                else:\n",
    "                    if not resampled:\n",
    "                        keys = sample(list(dict_solns.keys()), max_returned)\n",
    "                    else:\n",
    "                        keys = sample(list(dict_solns.keys()), int(max_soln*0.0025))\n",
    "                    dict_solns2 = {}\n",
    "                    for k in keys:\n",
    "                        dict_solns2[k] = dict_solns[k]\n",
    "                    sampled_solns = pd.DataFrame({'soln': dict_solns2}).reset_index(drop=True)\n",
    "                # Sort out the solutions at this point to save time later.\n",
    "                sampled_solns = sampled_solns.assign(soln = [list(np.sort(s)) for s in sampled_solns['soln']])\n",
    "                return soln_returned, sampled_solns, resampled\n",
    "            else:\n",
    "                soln_returned = False\n",
    "                return soln_returned, None, None\n",
    "    except RuntimeError:\n",
    "        soln_returned = False\n",
    "        return soln_returned, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "East\n",
    "East Midlands\n",
    "London\n",
    "North West\n",
    "South East\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'London'\n",
    "r = region.replace(\" \", \"_\")\n",
    "df = pd.read_csv(f\"Logs/DataFrames/df_{r}_3.csv.gz\")\n",
    "solver = const_mapper(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "const_pairs2 = const_pairs.query(\"region == @region\")\n",
    "const_tris2 = const_tris.query(\"region == @region\")\n",
    "const_quads2 = const_quads.query(\"region == @region\")\n",
    "name_cols = get_name_cols(const_tris2)\n",
    "# How many times should we rerun Algorithm X when we cannot return all solutions.\n",
    "RERUN_COUNTER = 5 #* (1 + (seats >= 4))\n",
    "# How many times should we rerun Algorithm X when we have to remove different sized sets.\n",
    "COUNTER = 5 #* (1 + (seats >= 4))\n",
    "\n",
    "seats = 3\n",
    "n = get_n(df, name_cols)\n",
    "\n",
    "file_name = f\"Solutions/solns_{r}_{seats}.csv.gz\"\n",
    "log_file_name = f\"Logs/log_{r}_{seats}.log\"\n",
    "log_df_name = f\"Logs/DataFrames/df_{r}_{seats}.csv.gz\"\n",
    "log = custom_logger(log_file_name)\n",
    "log.info(f'Starting code for region {region} with {seats} seats.')\n",
    "max_solns = 1e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the solutions multiple times with different random elements removed.\n",
    "soln_dict = {}\n",
    "i = 0\n",
    "removed = {}\n",
    "removed['triplet'] = [123]\n",
    "while i < COUNTER:\n",
    "#     df, removed = remove_random_const(const_pairs2, const_tris2, const_quads2, seats, region, n)\n",
    "    soln_returned, soln_dict[i], resampled = return_solutions(df, resampled=False, max_soln=max_solns, log_df_name=log_df_name)\n",
    "    if soln_returned:\n",
    "        if resampled:\n",
    "            d = {}\n",
    "            d[0] = soln_dict[i].copy()\n",
    "            j = 1\n",
    "            while j < RERUN_COUNTER and soln_returned:\n",
    "                if soln_returned:\n",
    "                    j += 1\n",
    "                    soln_returned, d[j], resampled = return_solutions(df, resampled=True, max_soln=max_solns, log_df_name=log_df_name)\n",
    "                else:\n",
    "                    break\n",
    "            if soln_returned:\n",
    "                soln_dict[i] = pd.concat(d)\n",
    "    if soln_returned:\n",
    "        # Add in the set_no's that were removed from the solutions\n",
    "        soln_dict[i][list(removed.keys())[0]] = str(list(removed.values())[0])\n",
    "        i += 1\n",
    "        solns = pd.concat(soln_dict)\n",
    "if len(solns) > 0:\n",
    "    solns = solns.assign(region = region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in regions:\n",
    "    print(region)\n",
    "    get_solns(const_pairs, const_tris, const_quads, 2, region, max_solns=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_solns(const_pairs, const_tris, const_quads, 2, \"South East\", max_solns=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "importlib.reload(sys.modules['algox_modules'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to run with joblib.\n",
    "element_information = Parallel(n_jobs=4, verbose=10)(\n",
    "    delayed(get_solns)(const_pairs, const_tris, const_quads, seats, region, max_solns=1e7) \n",
    "        for seats in [2,3,4] for region in regions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_solns(const_pairs, const_tris, const_quads, 3, 'Yorkshire and the Humber', max_solns=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in [2,3,4]:\n",
    "    get_solns(const_pairs, const_tris, const_quads, i, 'London', max_solns=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_solns(const_pairs, const_tris, const_quads, 3, 'Wales', max_solns=1e7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
