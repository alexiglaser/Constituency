{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation of results\n",
    "Using the solutions found from Algorithm X we'll now concatenate the results obtained using different voting methods so that, for each possible set of solutions (for each region and voting method) we can obtain the amount of seats that would have been won. This calculation takes some time so we are doing it here first which should speed up the calculations in 'predicted_results'ipynb' notebook.\n",
    "\n",
    "In these results we will also add in the following: \n",
    "\n",
    "1. the island constituencies of 'Isle of Wight', 'Orkney and Shetland', 'Ynys Mon', 'Na h-Eileanan an Iar'\n",
    "1. the results from ther constituencies in the Yorkshire and Humber region which had a ('Brigg and Goole', 'Scunthorpe', 'Cleethorpes', 'Great Grimsby'). \n",
    "\n",
    "Also note that the Speaker's constituency of 'Chorley' (in the 'North West' region) has not been included as it is always one and makes no difference to the overall result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from ast import literal_eval\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2h = pd.read_csv(\"../Data/MergedResults/const_merged_2_webster.csv.gz\")\n",
    "df3h = pd.read_csv(\"../Data/MergedResults/const_merged_3_webster.csv.gz\")\n",
    "df4h = pd.read_csv(\"../Data/MergedResults/const_merged_4_webster.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"../Data/SampledSolutions/sampled_solns_*.csv.gz\")\n",
    "predicted_seats_dict = {}\n",
    "for method in [\"dhondt\",\"webster\",\"huntington\",\"imperiali\",\"hare\",\"droop\"]:\n",
    "    df2h = pd.read_csv(f\"../Data/MergedResults/const_merged_2_{method}.csv.gz\")\n",
    "    df3h = pd.read_csv(f\"../Data/MergedResults/const_merged_3_{method}.csv.gz\")\n",
    "    df4h = pd.read_csv(f\"../Data/MergedResults/const_merged_4_{method}.csv.gz\")\n",
    "    for file in files:\n",
    "        init_dict = {}\n",
    "        seats = int(re.findall(\"[0-9]+\", file)[0])\n",
    "        region = re.sub(\"_[0-9]+.csv.gz\", \"\", file.replace(\"../Data/SampledSolutions/sampled_solns_\", \"\"))\n",
    "        key = method + \"_\" + region + \"_\" + str(seats)\n",
    "        region = region.replace(\"_\", \" \")\n",
    "        # Use literal eval since we can have multiple values there.\n",
    "        if seats < 4:\n",
    "            df = pd.read_csv(file, dtype={'region': str}, converters={'soln': literal_eval})\n",
    "        else:\n",
    "            df = pd.read_csv(file, dtype={'region': str}, converters={'soln': literal_eval, 'triplet': literal_eval})\n",
    "        # Counter for the key of the dictionary that will eventually form the \n",
    "        i = 0\n",
    "        for index, row in df.iterrows():\n",
    "            i += 1\n",
    "            if seats == 2:\n",
    "                df_seats = df2h[df2h['set_no'].isin(row['soln'])]\n",
    "                if 'triplet' in df.columns:\n",
    "                    df_seats = pd.concat([df_seats, df3h[df3h['set_no'] == row['triplet']]], sort=False)\n",
    "            elif seats == 3:\n",
    "                df_seats = df3h[df3h['set_no'].isin(row['soln'])]\n",
    "                if 'pair' in df.columns:\n",
    "                    df_seats = pd.concat([df_seats, df2h[df2h['set_no'] == row['pair']]], sort=False)\n",
    "                if 'quad' in df.columns:\n",
    "                    df_seats = pd.concat([df_seats, df4h[df4h['set_no'] == row['quad']]], sort=False)\n",
    "            elif seats == 4:\n",
    "                df_seats = df4h[df4h['set_no'].isin(row['soln'])]\n",
    "                if 'triplet' in df.columns:\n",
    "                    if type(row['triplet']) == list:\n",
    "                        df_seats = pd.concat([df_seats, df3h[df3h['set_no'].isin(row['triplet'])]], sort=False)\n",
    "                    else:\n",
    "                        df_seats = pd.concat([df_seats, df3h[df3h['set_no'] == row['triplet']]], sort=False)\n",
    "            init_dict[i] = df_seats.fillna(0).apply(sum)\n",
    "        predicted_seats_dict[key] = pd.concat(init_dict, axis=1, sort=False).T\n",
    "        predicted_seats_dict[key] = predicted_seats_dict[key].assign(region = region, seats=seats, method = method)\n",
    "        # Have to add in the island constituencies which have been kept separate and allocate them on a FPTP method\n",
    "        if region == \"Scotland\":\n",
    "            predicted_seats_dict[key][\"Liberal Democrat\"] += 1\n",
    "            predicted_seats_dict[key][\"Scottish National Party\"] += 1\n",
    "        elif region == \"Wales\" or region == \"South East\":\n",
    "            predicted_seats_dict[key][\"Conservative\"] += 1\n",
    "        # In addition have to manually enter back in four seats from 'Yorkshire & the Humber' region due to\n",
    "        # a circular argument.\n",
    "        elif region == \"Yorkshire and The Humber\":\n",
    "            # When we have a 4 seat grouping it was always split the same way. For fewer than 4 we had a few differences.\n",
    "            if seats == 4:\n",
    "                predicted_seats_dict[key][\"Conservative\"] += 3\n",
    "                predicted_seats_dict[key][\"Labour\"] += 1\n",
    "            else:\n",
    "                if method in ['dhondt', 'huntington', 'imperiali', 'droop']:\n",
    "                    predicted_seats_dict[key][\"Conservative\"] += 4\n",
    "                else:\n",
    "                    predicted_seats_dict[key][\"Conservative\"] += 2\n",
    "                    predicted_seats_dict[key][\"Labour\"] += 2\n",
    "        predicted_seats_dict[key] = predicted_seats_dict[key].drop(columns='set_no')\n",
    "predicted_seats = pd.concat(predicted_seats_dict, sort=False)\n",
    "predicted_seats = predicted_seats.sort_values(['region','seats'])\n",
    "predicted_seats = predicted_seats.reset_index(drop=True)\n",
    "\n",
    "predicted_seats.to_csv(\"../Data/predicted_seats.csv.gz\", index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
